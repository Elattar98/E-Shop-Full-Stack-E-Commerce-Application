from `\\r\\n` to `\\n`) when processing ICU\n   * expressions.\n   *\n   * If `true` then we will normalize ICU expression line endings.\n   * The default is `false`, but this will be switched in a future major release.\n   */\n  i18nNormalizeLineEndingsInICUs?: boolean;\n  /**\n   * An array of characters that should be considered as leading trivia.\n   * Leading trivia are characters that are not important to the developer, and so should not be\n   * included in source-map segments.  A common example is whitespace.\n   */\n  leadingTriviaChars?: string[];\n  /**\n   * If true, do not convert CRLF to LF.\n   */\n  preserveLineEndings?: boolean;\n}\n\nexport function tokenize(\n    source: string, url: string, getTagDefinition: (tagName: string) => TagDefinition,\n    options: TokenizeOptions = {}): TokenizeResult {\n  const tokenizer = new _Tokenizer(new ParseSourceFile(source, url), getTagDefinition, options);\n  tokenizer.tokenize();\n  return new TokenizeResult(\n      mergeTextTokens(tokenizer.tokens), tokenizer.errors, tokenizer.nonNormalizedIcuExpressions);\n}\n\nconst _CR_OR_CRLF_REGEXP = /\\r\\n?/g;\n\nfunction _unexpectedCharacterErrorMsg(charCode: number): string {\n  const char = charCode === chars.$EOF ? 'EOF' : String.fromCharCode(charCode);\n  return `Unexpected character \"${char}\"`;\n}\n\nfunction _unknownEntityErrorMsg(entitySrc: string): string {\n  return `Unknown entity \"${entitySrc}\" - use the \"&#<decimal>;\" or  \"&#x<hex>;\" syntax`;\n}\n\nfunction _unparsableEntityErrorMsg(type: CharacterReferenceType, entityStr: string): string {\n  return `Unable to parse entity \"${entityStr}\" - ${\n      type} character reference entities must end with \";\"`;\n}\n\nenum CharacterReferenceType {\n  HEX = 'hexadecimal',\n  DEC = 'decimal',\n}\n\nclass _ControlFlowError {\n  constructor(public error: TokenError) {}\n}\n\n// See https://www.w3.org/TR/html51/syntax.html#writing-html-documents\nclass _Tokenizer {\n  private _cursor: CharacterCursor;\n  private _tokenizeIcu: boolean;\n  private _interpolationConfig: InterpolationConfig;\n  private _leadingTriviaCodePoints: number[]|undefined;\n  private _currentTokenStart: CharacterCursor|null = null;\n  private _currentTokenType: TokenType|null = null;\n  private _expansionCaseStack: TokenType[] = [];\n  private _inInterpolation: boolean = false;\n  private readonly _preserveLineEndings: boolean;\n  private readonly _escapedString: boolean;\n  private readonly _i18nNormalizeLineEndingsInICUs: boolean;\n  tokens: Token[] = [];\n  errors: TokenError[] = [];\n  nonNormalizedIcuExpressions: Token[] = [];\n\n  /**\n   * @param _file The html source file being tokenized.\n   * @param _getTagDefinition A function that will retrieve a tag definition for a given tag name.\n   * @param options Configuration of the tokenization.\n   */\n  constructor(\n      _file: ParseSourceFile, private _getTagDefinition: (tagName: string) => TagDefinition,\n      options: TokenizeOptions) {\n    this._tokenizeIcu = options.tokenizeExpansionForms || false;\n    this._interpolationConfig = options.interpolationConfig || DEFAULT_INTERPOLATION_CONFIG;\n    this._leadingTriviaCodePoints =\n        options.leadingTriviaChars && options.leadingTriviaChars.map(c => c.codePointAt(0) || 0);\n    const range =\n        options.range || {endPos: _file.content.length, startPos: 0, startLine: 0, startCol: 0};\n    this._cursor = options.escapedString ? new EscapedCharacterCursor(_file, range) :\n                                           new PlainCharacterCursor(_file, range);\n    this._preserveLineEndings = options.preserveLineEndings || false;\n    this._escapedString = options.escapedString || false;\n    this._i18nNormalizeLineEndingsInICUs = options.i18nNormalizeLineEndingsInICUs || false;\n    try {\n      this._cursor.init();\n    } catch (e) {\n      this.handleError(e);\n    }\n  }\n\n  private _processCarriageReturns(content: string): string {\n    if (this._preserveLineEndings) {\n      return content;\n    }\n    // https://www.w3.org/TR/html51/syntax.html#preprocessing-the-input-stream\n    // In order to keep the original position in the source, we can not\n    // pre-process it.\n    // Instead CRs are processed right before instantiating the tokens.\n    return content.replace(_CR_OR_CRLF_REGEXP, '\\n');\n  }\n\n  tokenize(): void {\n    while (this._cursor.peek() !== chars.$EOF) {\n      const start = this._cursor.clone();\n      try {\n        if (this._attemptCharCode(chars.$LT)) {\n          if (this._attemptCharCode(chars.$BANG)) {\n            if (this._attemptCharCode(chars.$LBRACKET)) {\n              this._consumeCdata(start);\n            } else if (this._attemptCharCode(chars.$MINUS)) {\n              this._consumeComment(start);\n            } else {\n              this._consumeDocType(start);\n            }\n          } else if (this._attemptCharCode(chars.$SLASH)) {\n            this._consumeTagClose(start);\n          } else {\n            this._consumeTagOpen(start);\n          }\n        } else if (!(this._tokenizeIcu && this._tokenizeExpansionForm())) {\n          // In (possibly interpolated) text the end of the text is given by `isTextEnd()`, while\n          // the premature end of an interpolation is given by the start of a new HTML element.\n          this._consumeWithInterpolation(\n              TokenType.TEXT, TokenType.INTERPOLATION, () => this._isTextEnd(),\n              () => this._isTagStart());\n        }\n      } catch (e) {\n        this.handleError(e);\n      }\n    }\n    this._beginToken(TokenType.EOF);\n    this._endToken([]);\n  }\n\n  /**\n   * @returns whether an ICU token has been created\n   * @internal\n   */\n  private _tokenizeExpansionForm(): boolean {\n    if (this.isExpansionFormStart()) {\n      this._consumeExpansionFormStart();\n      return true;\n    }\n\n    if (isExpansionCaseStart(this._cursor.peek()) && this._isInExpansionForm()) {\n      th